{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import fileio, filtering, kmers, analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and filter all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSeqs = fileio.readData(\"./data/\")\n",
    "\n",
    "allSeqs_filtered = filtering.filter_by_coverage(allSeqs, threshold=0.7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define settings and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 255     # number of permutations\n",
    "k = 8       # kmer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allKmers = {exp: kmers.toKmers(df, kmer_size=k) for exp, df in allSeqs_filtered.items()}\n",
    "\n",
    "# weighting of kmers\n",
    "df = pd.DataFrame.from_dict(allKmers, orient=\"columns\").fillna(0)\n",
    "kmermatrix = np.array([df[exp] for exp in df.columns])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Minhashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import WeightedMinHashGenerator\n",
    "\n",
    "n_repetitions = 30\n",
    "allSignatures_byrun = [None]*n_repetitions\n",
    "allBinarySignatures_byrun = [None]*n_repetitions\n",
    "\n",
    "for i in range(n_repetitions):\n",
    "    wmg = WeightedMinHashGenerator(kmermatrix.shape[1], sample_size=m, seed=i)\n",
    "    allSignatures_byrun[i] = {exp: np.mod(w.digest()[:,0], 256) for exp, w in zip(allKmers.keys(), wmg.minhash_many(kmermatrix))}\n",
    "    allBinarySignatures_byrun[i] = {exp: ''.join([bin(s)[2:].zfill(8) for s in sig]) for exp, sig in allSignatures_byrun[i].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woverlaps_byrun = np.zeros((n_repetitions, 39, 39))\n",
    "for i, rep in enumerate(allSignatures_byrun):\n",
    "    woverlaps_byrun[i] = np.array([[sum(np.array(s1) == np.array(s2))/m for s1 in rep.values()] for s2 in rep.values()])\n",
    "\n",
    "woverlaps = np.mean(woverlaps_byrun, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hammings_byrun = np.zeros((n_repetitions, 39, 39))\n",
    "\n",
    "for i, rep in enumerate(allBinarySignatures_byrun):\n",
    "    hammings_byrun[i] = np.array([[sum([ord(a) ^ ord(b) for a, b in zip(s1, s2)])/len(s1) for s1 in rep.values()] for s2 in rep.values()])\n",
    "\n",
    "hammings = np.mean(hammings_byrun, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reedsolo import RSCodec, ReedSolomonError\n",
    "\n",
    "\n",
    "# A fuzzy extractor via the code offset construction\n",
    "class fuzzy_extractor:\n",
    "\n",
    "    def __init__(self, r, n):\n",
    "        # int r: number of error correcting symbols\n",
    "        # int n: number of information symbols\n",
    "        self.r = r\n",
    "        self.rsc = RSCodec(r)\n",
    "        self.n = n   \n",
    "\n",
    "    def bytearraysubstraction(self, a, b):\n",
    "        res = bytearray(len(a))\n",
    "        for i in range(len(a)):\n",
    "            res[i] = ( a[i] - b[i] ) % 256\n",
    "        return res \n",
    "    \n",
    "    def encode(self, w):\n",
    "        w = bytearray(w)\n",
    "        # choose a codeword uniformly at random        \n",
    "        inf = bytearray(np.random.randint(256, size = self.n-self.r).tolist())\n",
    "        c = self.rsc.encode(inf)\n",
    "        if len(c) != self.n:\n",
    "            raise Exception('RSCodec unexpeced behavior')\n",
    "        # h = w - c\n",
    "        h = self.bytearraysubstraction(w, c)\n",
    "        return inf, h\n",
    "    \n",
    "    def decode(self, wdash, h):\n",
    "        wdash = bytearray(wdash)\n",
    "        # c = w - h\n",
    "        diff = self.bytearraysubstraction(wdash, h)\n",
    "        try:\n",
    "            decoded_msg, _, _ = self.rsc.decode(diff)\n",
    "        except ReedSolomonError as e:\n",
    "            decoded_msg = None\n",
    "        \n",
    "        return decoded_msg\n",
    "\n",
    "\n",
    "def test_fuzzy_extractor(fuz_ext, seq1, seq2):\n",
    "    w = bytearray(seq1)\n",
    "    wdash = bytearray(seq2)\n",
    "\n",
    "    key, helper = fuz_ext.encode(w)\n",
    "    key_dash = fuz_ext.decode(wdash, helper)\n",
    "    return key == key_dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuz_ext = fuzzy_extractor(r=m-32, n=m) # r = redundancy, n = length of the codeword\n",
    "key_byrun = np.zeros((n_repetitions, 39, 39))\n",
    "\n",
    "for i, rep in enumerate(allSignatures_byrun):\n",
    "    key_byrun[i] = np.array([[test_fuzzy_extractor(fuz_ext, list(s1), list(s2)) for s1 in rep.values()] for s2 in rep.values()])\n",
    "\n",
    "key = np.mean(key_byrun, axis=0, dtype=float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"./results_analysis/minhash_overlaps.csv\", woverlaps, delimiter=\",\")\n",
    "np.savetxt(\"./results_analysis/minhash_hamming.csv\", hammings, delimiter=\",\")\n",
    "np.savetxt(\"./results_analysis/minhash_fuzzykeys.csv\", key, delimiter=\",\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_matrix(woverlaps).show()\n",
    "\n",
    "positive_matrix, negative_matrix = analysis.generate_truthtables()\n",
    "fig = analysis.plot_hists(woverlaps, positive_matrix, negative_matrix)\n",
    "fig.show()\n",
    "fig.write_image(\"./results_analysis/unconstrained_minhash_overlaps.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_matrix(hammings).show()\n",
    "\n",
    "positive_matrix, negative_matrix = analysis.generate_truthtables()\n",
    "fig = analysis.plot_hists(hammings, positive_matrix, negative_matrix)\n",
    "fig.show()\n",
    "fig.write_image(\"./results_analysis/unconstrained_minhash_hamming.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_matrix(key).show()\n",
    "\n",
    "positive_matrix, negative_matrix = analysis.generate_truthtables()\n",
    "fig = analysis.plot_hists(key, positive_matrix, negative_matrix)\n",
    "fig.show()\n",
    "fig.write_image(\"./results_analysis/unconstrained_fuzzy_keys.svg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constrained dataets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_matrix(woverlaps).show()\n",
    "\n",
    "to_exclude = set([16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 33, 34, 37, 38])\n",
    "positive_matrix, negative_matrix = analysis.generate_truthtables(to_exclude)\n",
    "fig = analysis.plot_hists(woverlaps, positive_matrix, negative_matrix)\n",
    "fig.show()\n",
    "fig.write_image(\"./results_analysis/constrained_minhash_overlaps.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_matrix(hammings).show()\n",
    "\n",
    "to_exclude = set([16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 33, 34, 37, 38])\n",
    "positive_matrix, negative_matrix = analysis.generate_truthtables(to_exclude)\n",
    "fig = analysis.plot_hists(hammings, positive_matrix, negative_matrix)\n",
    "fig.show()\n",
    "fig.write_image(\"./results_analysis/constrained_minhash_hamming.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_matrix(key).show()\n",
    "\n",
    "to_exclude = set([16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 33, 34, 37, 38])\n",
    "positive_matrix, negative_matrix = analysis.generate_truthtables(to_exclude)\n",
    "fig = analysis.plot_hists(key, positive_matrix, negative_matrix)\n",
    "fig.show()\n",
    "fig.write_image(\"./results_analysis/constrained_fuzzy_keys.svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "np_pd_sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da8130b5c8ccf41f100662caf67f3ba756beedabd599674f9119b95438e5e458"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
